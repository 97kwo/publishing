- 데로뉴 : LG 스마트팩토리의 동태
	- 페러다임 변화 - 독립된 공간에서 혼자 일하는 로봇에서 협력로봇으로 변화 (사람과 같이 일)
	- 시스템을 파는 기업
https://github.com/JD-edu/deep_learning_class
https://github.com/gilbutITbook/080324?tab=readme-ov-file
https://github.com/taehojo/data/blob/master/ThoraricSurgery3.csv
## 텐서플로우 
### 텐서플로우
- 머신러닝 프레임워크(라이브러리)
- 신경망,역전파,순전파, 추론
### Keras
##### Keras 라이브러리
- Sequential
- Functianla 
- Subclassing
##### 신경망 모델 생성
1. 손실함수 (loss function) : 평균제곱오차와 같은 오차 함수
2. 옵티마이저 : 경사하강법, SGD등의 (모델의 매개변수(weight, bias)를 업데이트 하는 방법)
3. 측정항목 : accuracy 또는 loss
##### 손실함수
1. 평균제곱오차 - 선형회기
2. 평균절대오차
3. 이진 크로스 엔트로피 손실 - 이진분류
4. 다중 클래스 엔트로피 손실
##### 옵티마이저
1. 경사하강법
2. 확률적 경사 하강법 : 특정 샘플들만 사용 (learning rate와 특정샘플 - local minimum 회피, **속도**)
   `keras.optimezers.SGD(lr=0.1)`
   `keras.optimezers.SGD(lr=0.1,momentum=0.1)`
   `keras.optimizers.Adam(lr, beta_1, beta_2, epsilon, decay)`
3. 모멘텀을 적용한 경사 하강법
##### 측정함수
1. 정확도 : 성공/전체
2. 정밀도 : 긍정적으로 예측한 샘플 중에서 실제로 긍정인 샘플의 비율
##### 선형회기 실습
- 함수 불러오기
	- sequential : 틀을 만들어줌
	- Dense : Layer층을 구분
- 데이터 불러오기
	- mnist, Cifar10
	- x = np.array([2,4,6,8])
	- y = np.array([81,93,91,97])
- 층 만들기 lr
	- model.add(Dense(1, input_dim=1, activation = linear)
		- 1 : 출력갯수, **input_dim** : 인풋 갯수, linear : 선형
- 모델 전달하기
	- model.compile(optimizer='sgd',loss='mse')
- 모델 학습
	- model.fit(x,y,epochs=2000)
- 모델 결과
	- plt.scatter
	- model.predict(x)
	- prediction = model.predict([hour])
##### 디중 선형회기 실습
- 함수 불러오기
	- sequential : 틀을 만들어줌
	- Dense : Layer층을 구분
- 데이터 불러오기
	- mnist, Cifar10
	- x = np.array([2,4,6,8]) > 2 array로
	- y = np.array([81,93,91,97])
- 층 만들기 lr
	- model.add(Dense(2, input_dim=1, activation = linear)
		- 1 : 출력갯수, **input_dim** : 인풋 갯수, linear : 선형
- 모델 전달하기
	- model.compile(optimizer='sgd',loss='mse')
- 모델 학습
	- model.fit(x,y,epochs=2000)
- 모델 결과
	- plt.scatter
	- model.predict(x)
	- prediction = model.predict([hour])
##### 로지스틱 회귀
![[Pasted image 20240205103425.png]]
- 분류 VS 회귀
	- 분류 : 0 아니면 1의 결과값
	- 회귀 : 0~1의 결과값
- activation : sigmoid, tanh 등등
- loss : binary_crossentropy
##### 레모네이드 (CSV 다운로드)
- 기본 옵티마이저는 아담으로 잡힌다.
- `model = tf.keras.models.Model(X,Y)` : 입력층 X, 출력층 Y
##### 인디언 당뇨 예측 (다중 선형회귀)
- data 전처리를 하고 상관관계 분석
- 그 이후 주요 parameters들을 뽑아준 후 분석
##### 꽃 분류 (다중 분류)
- 원핫 인코딩
- softmax
  ![[Pasted image 20240205142806.png]]
  ![[Pasted image 20240205143010.png]]https://inhovation97.tistory.com/32
  - **데이터 분석하는게 가장 중요함**
##### 검증데이터의 필요성
- 과적합 방지 및 다른 데이터 예측 정확도 향상
- test split
  `X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)`
- 모델 저장 (전이학습을 위해서)
    `model.save('my_best_model.h5')`
    `model = load_model(;my_best_model.h5)`
    `score=model.evaluate(X_test, y_test)`
    `print('Test accuracy:', score[1])`
    - 최고모델 저장
```ad-note
~~~python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import ModelCheckpoint

# 모델 생성
model = Sequential()
model.add(Dense(16, input_dim=8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ModelCheckpoint 콜백 설정
checkpoint_path = "best_model.h5"
checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

# 가상의 데이터 생성 (실제 데이터로 대체해야 함)
X_train = tf.random.normal((100, 8))
y_train = tf.random.uniform((100, 1), maxval=2, dtype=tf.int32)
X_val = tf.random.normal((20, 8))
y_val = tf.random.uniform((20, 1), maxval=2, dtype=tf.int32)

# 모델 훈련
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[checkpoint])

# 저장된 모델 불러오기
best_model = tf.keras.models.load_model(checkpoint_path)

# 저장된 모델 확인
best_model.summary()>)
```

- **k겹 교차 검증**
	- 테스트 셋이 적을 때![[Pasted image 20240205153216.png]]
	- 그러면 k겹 교차검증이아닌 0.7학습, 0.3검증을 할때 1에폭마다 w와b가 업데이트 되는거야 아니면 1에폭 내에서도 계속해서 w와b가 업데이트 되는거야?
	- 훈련 데이터를 70%로 사용하고 검증 데이터를 30%로 사용하는 경우, 각 에폭 내에서도 계속해서 가중치와 편향이 업데이트됩니다. 에폭은 전체 훈련 데이터를 한 번 훑는 것을 말하며, 각 에폭이 끝날 때마다 모델의 가중치와 편향이 업데이트됩니다.
		일반적으로 한 에폭 내에서의 가중치 업데이트는 미니배치 경사 하강법에서 이루어집니다. 미니배치는 전체 훈련 데이터에서 임의로 선택한 작은 일부 데이터 그룹입니다. 모델은 미니배치에 대한 손실을 계산하고, 해당 손실을 최소화하기 위해 가중치를 업데이트합니다. 이 과정이 한 번 수행되면 한 번의 "반복(iteration)"이라고 합니다. 에폭은 전체 훈련 데이터를 한 번 모두 사용하여 이러한 반복을 완료하는 것을 말합니다.
		따라서 1에폭 내에서도 여러 번의 가중치 업데이트가 이루어지며, 각 미니배치에 대한 손실을 줄이기 위해 가중치가 조정됩니다.
		- w와 b1 업데이트 과정
			1겹 결과 w1,b1
			2겹 인풋 w1,b1 결과 w2,b2...
			5겹 인풋 w4,b4 결과 w5,b5
			1겹 인풋 w5,b5 결과 w6,b6...
		![[Pasted image 20240205160540.png]]
### Mnist 분류 - DNN (실습)
##### mnist 분석
- 0~9에 대한 6만개의 손글씨 데이터
- CNN이 아닌 DNN으로 학습 가능
- tensorflow mnist (Google) 참조
  ![[Pasted image 20240205160813.png]]
  ##### mnist 데이터 전처리
  - 28 x 28의 784개 데이터를 reshape (2차원을 1차원으로 변환)
	  - `(X_train, y_train), (X_test, y_test) = mnist.load_data()`
	  - `X_train = X_train.reshape(X_train.shape[0],784)`
	  - `X_train = X_train.astype("float64")/255
	- fully connected layer < - > Dropout
```python
from tensorflow.keras.models import load_model
import cv2
import numpy as np
import matplotlib.pyplot as plt
# 모델 로드
loaded_model = load_model('h_bset_model.h5')

# 테스트할 이미지들의 파일 경로 리스트
image_paths = ['0.png', '1.png', '2.png', '3.png', '4.png',

               '5.png', '6.png', '7.png', '8.png', '9.png']

# 이미지 예측 및 피규어에 표시
plt.figure(figsize=(12, 6))
for i, image_path in enumerate(image_paths, 1):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is not None:
        img = cv2.resize(img, (28, 28))
        img = cv2.bitwise_not(img)  # 흑백 반전
        img = img.astype('float32') / 255
        img = np.expand_dims(img, axis=-1)  # 차원 확장 (28, 28, 1)로 만들기
        img = img.reshape(1, 784)
        # 모델 예측
        prediction = loaded_model.predict(img)
        predicted_label = np.argmax(prediction)
        # 이미지 및 예측 결과 피규어에 추가
        plt.subplot(2, 5, i)
        plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))
        plt.title(f'P: {predicted_label}')
        plt.axis('off')
plt.tight_layout()
plt.show()
```

![[Pasted image 20240205173458.png]]
![[Pasted image 20240205171958.png]]

### 내일 예고
- CNN, YOLO 등을 이용한 객체인식
- Convolution 방식 vs Fully Connected
	- 합성곱 신경망(Convolutional Neural Network, CNN)은 완전 연결 신경망(Fully Connected Neural Network)과는 다른 구조를 가지고 있습니다. CNN은 주로 이미지 처리에 사용되며, 합성곱(Convolution)과 풀링(Pooling) 층으로 구성되어 있습니다. 이러한 구조는 지역적인 특징을 감지하고 전체 이미지에 대한 특징을 추출하는 데 효과적입니다. Fully Connected 신경망은 모든 뉴런이 서로 연결되어 있는 구조로, 입력 데이터의 전체 특징을 고려하여 출력을 계산합니다.
	- CNN은 완전 연결 신경망과는 다르게 모든 뉴런이 서로 연결되어 있지 않습니다. CNN은 주로 합성곱층과 풀링층으로 이루어져 있습니다. 합성곱층에서는 지역적인 특징을 감지하고, 풀링층에서는 감지된 특징을 축소하여 전체적인 특징을 추출합니다. 이러한 구조는 이미지 처리에서 효과적으로 사용되며, 이미지의 지역적인 패턴을 인식하는 데 강점을 가지고 있습니다.
- 아두이노에서도 사용 가능한 tensorflow-lite