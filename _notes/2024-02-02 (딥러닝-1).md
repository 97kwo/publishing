- 강사님 전문 : 라즈베리파이4 딥러닝
## 딥러닝의 역사
### 인공지능
 - 가장 포괄적인 개념
### 머신러닝 (피처 추출 및 알고리즘에 인풋)
- 반드시 데이터가 있어야 함
- 데이터 기반 학습, 문제해결을 위한 알고리즘
- 규칙을 알고리즘을 통해서 특징을 찾아냄 - **패턴화**
	- 지도학습
		- 데이터를 줄 때 정답을 알려준다
		- 분류 (패턴, 특징)
	- 비지도학습
		- 그냥 데이터셋만 인풋으로
		- 비슷한 특징끼리 알아서 분류(스마트 팩토리)
		- 알아서 특징을 추출
	- 강화학습
		- 알파고
### 딥러닝
- 레이블링과 독립변수
- 자극의 임계점보다 높으면 시냅스로
- **은닉층**(Hidden Layer)
- 머신러닝이 못하는 것들 (이미지-객체인식, 음성인식, 자연어 처리)
- RNN, GAN등에 활용
- **상관관계**가 있다면 딥러닝을 사용가능, 수치적 통계
### 딥러닝의 역사
##### 인공지능 태동기
- MCP 뉴런
- 1950년 엘런튜링의 튜링테스트 (이미테이션 게임)
##### 인공지능 황금기
- **퍼셉트론**
##### 1차 AI 겨울
- 컴퓨터 성능의 한계
##### 1차 AI 봄
- 전문가 시스템
- 실패하고 바로 2차 겨울
### 인공지능의 시작
##### 인공신경망의 아이디어
- 퍼셉트론의 실현 : 입력값, 웨이트, 출력
  ![[Pasted image 20240202114114.png|300]]
- 좌,우 화살표 학습 및 구분
- 남성, 여성 사진 학습 및 구분
##### 신경망 VS 인공신경망
- 신경망 : 시냅스에서 일정 자극의 크기 여부에 따라 전달여부 판단
- 신경망을 이루는 가장 중요한 기본단위는 퍼셉트론(**가장 작은 신경망의 단위**)
- 강도 : Weight를 통한 가중합
- 깊이 : Layer 와 Activation function
##### 신경망의 용어들
- 기울기 a는 퍼셉트론에서 가중치(중요도)를 의미하는 w로 표기
- y절편 b는 bias
- 가중합 : w * x + b
- 입력값을 넣고 w와 b를 조절하며 원하는 아웃풋 - **4가지 과정을 통해서**
##### 퍼셉트론의 구조 및 동작원리
- 입력신호들을 가중치와 곱한다 :  > **가중합**을 통하여 **트레이닝(학습)**
- 가중합에 활성화 함수에 입력
- 활성화함수의 결과값을 얻는다
- 특정 입력값에 대해서 정해진 결과값이 필요함 > **퍼셉트론의 학습 = 가중치와 편향의 조정**
##### 퍼셉트론의 한계
- AND와 OR연산 해결 가능
- 하지만 XOR을 해결하지 못 함
- 단층 퍼셉트론의 한계, 다층 퍼셉트론의 등장 - **은닉층**과 은닉층의 학습을 위한 **역전파법**
- 레이어를 추가할수록 정확도가 낮아진다?
- 활성화 함수의 등장 : 은닉층과 출력층의 뉴런에서 출력 값을 결정하는 함수
- **sigmoid함수의 최대치가 0.3** 으로 층을 거쳐갈수록 기울기 소실 (최대값이 0.3)

### 역전파법, 로스함수, 체인룰이론 및 파이썬 실습 
##### DNN(딥러닝)의 7단계
1. 순전파 (가중치 = 강도)
2. 평균제곱오차 (**loss function**)와 경사하강법 (**optimizer**)
3. 역전파오차 
4. 입력 역전파
5. 가중치/편향 순전파
6. 가중치/편향 역전파
7. 신경망 학습 - lr

- 노드가 하나인 단일 퍼셉트론
```ad-note
~~~python

```
##### 체인룰이란?
- 오차 역전파 사용 시 w,b 값을 조절해주기 위하여